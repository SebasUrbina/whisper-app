import streamlit as st
import numpy as np
import time
import whisper
import os

# Contexto
st.title('Whisper APP')
st.markdown('')

model_size = st.selectbox(
    'Selecciona el tama√±o del modelo',
    ('tiny', 'base', 'small', 'medium', 'large'))

# Model size
if model_size:
    st.write(f'Has elegido el modelo: **whisper-{model_size}**')
    if model_size == 'medium':
        st.warning('Debes tener tener al menos 5GB VRAM', icon="‚ö†Ô∏è")
    elif model_size == 'large':
        st.warning('Debes tener tener al menos 10GB VRAM', icon="‚ö†Ô∏è")

    with st.spinner('Cargando modelo'):
        try:
            # Si hay problemas de recursos
            # @st.cache
            # def load_model():
            #     model = whisper.load_model(model_size)
            # model = load_model()
            model = whisper.load_model(model_size)
        except:
            st.error(
                'No tienes suficiente VRAM, prueba con un modelo m√°s peque√±o', icon="üö®")

    audio_file = st.file_uploader("Suba el archivo mp3 a transcribir")
    # Cargar audio
    if audio_file is not None:
        st.audio(audio_file, format='audio/wav')
        audio_name = audio_file.name
        with open(audio_name, 'wb') as f:
            f.write(audio_file.read())

        # Cargar modelo
        if st.button('Transcribir audio'):
            # st.warning('Transcribiendo audio...', icon="‚ö†Ô∏è")
            # Transcribir
            with st.spinner('Transcribiendo audio'):
                output = model.transcribe("./"+audio_name)
                transcripcion = output['text']
                lang = output['language']
            st.success('Audio transcrito correctamente', icon="‚úÖ")
            st.write(f'Lenguaje detectado: {lang}')
            output_text = st.text_area(
                'Transcripci√≥n', transcripcion, height=150, label_visibility='hidden')
        os.remove(audio_name)
